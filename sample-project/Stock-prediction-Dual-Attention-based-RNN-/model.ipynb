{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.autograd import Variable\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df=pd.read_csv('data/train.csv')\n",
    "validation_df=pd.read_csv('data/validation.csv')\n",
    "validation_df=pd.concat([train_df[-9:],validation_df])\n",
    "validation_df=validation_df.reset_index(drop=True)\n",
    "test_df=pd.read_csv('data/test.csv')\n",
    "train_df.drop(['High price', 'Low Price', 'Date'],axis=1,inplace=True)\n",
    "validation_df.drop(['High price', 'Low Price', 'Date'],axis=1,inplace=True)\n",
    "test_df.drop(['High price', 'Low Price','Date'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class dataprep(Dataset):\n",
    "    def __init__(self, dataframe):\n",
    "        self.df=dataframe\n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]-10\n",
    "    def __getitem__(self,idx):\n",
    "        if (idx+10<self.df.shape[0]):\n",
    "            X=torch.from_numpy(self.df.drop('Closing Price',axis=1)[idx:idx+10].values)\n",
    "            targets=torch.from_numpy(self.df['Closing Price'][idx:idx+9].values)\n",
    "            y=torch.tensor([self.df['Closing Price'].loc[idx+9]])\n",
    "            return ({'X':X, 'targets':targets, 'y': y})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set=dataprep(dataframe=train_df)\n",
    "validation_set=dataprep(dataframe=validation_df)\n",
    "test_set=dataprep(dataframe=test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60 torch.Size([10, 16]) torch.Size([9]) torch.Size([1])\n",
      "61 torch.Size([10, 16]) torch.Size([9]) torch.Size([1])\n",
      "62 torch.Size([10, 16]) torch.Size([9]) torch.Size([1])\n"
     ]
    }
   ],
   "source": [
    "for i in range(60,63):\n",
    "    sample=validation_set[i]\n",
    "    print (i,sample['X'].size(),sample['targets'].size(), sample['y'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "870"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_set, batch_size=15, shuffle=True)\n",
    "val_loader = DataLoader(validation_set, batch_size=1, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self,encoder_input_size=16,encoder_hidden_size=64, time_steps=10):\n",
    "        super(EncoderRNN,self).__init__()\n",
    "        self.input_size=encoder_input_size\n",
    "        #input_size=n\n",
    "        self.hidden_size=encoder_hidden_size\n",
    "        #hidden_size=1\n",
    "        self.t_steps=time_steps\n",
    "        #time_steps=10\n",
    "        \n",
    "        self.input_attention=nn.Linear(time_steps+encoder_hidden_size,1)\n",
    "        self.rnn=nn.GRU(self.input_size, self.hidden_size)\n",
    "        \n",
    "    def forward(self,encoder_input,batch_size,hidden):\n",
    "        #encoder_input:batch,T,n\n",
    "        encoder_input=encoder_input.permute(0,2,1) #batch,n,T\n",
    "        #print (encoder_input.size())\n",
    "        #hidden=self.initHidden(batch_size) #hidden : 1,batch,hidden_size\n",
    "        #print (hidden.size())\n",
    "        encoded = torch.zeros(batch_size, self.t_steps, self.hidden_size,device=device) #encoded: 1,T,hidden_size\n",
    "        #print(encoded.size())\n",
    "        for t in range(self.t_steps):\n",
    "            x=torch.cat((hidden.repeat(self.input_size,1,1).permute(1,0,2),encoder_input),dim=2)\n",
    "            #print (x.size())\n",
    "            #x:batch,n,T+hidden_size\n",
    "            x=x.view(-1,self.t_steps+self.hidden_size)\n",
    "            #print (x.size())\n",
    "            #x:batch*n,T+hidden_size\n",
    "            x=F.softmax((self.input_attention(x)).view(-1,self.input_size),dim=1)\n",
    "            #print (x.size())\n",
    "            #print(encoder_input[:,t,:].size())\n",
    "            #x:batch,n\n",
    "            x=torch.mul(x,encoder_input[:,:,t])\n",
    "            #print (x.size())\n",
    "            #x:1,n\n",
    "            output, hidden=self.rnn(x.unsqueeze(0), hidden)\n",
    "            #print (output.size(), hidden.size())\n",
    "            encoded[:,t,:]=hidden\n",
    "            #output,hidden:1,1,hidden\n",
    "        return encoded\n",
    "    \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(1, batch_size, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self,decoder_hidden_size=64,encoder_hidden_size=64,decoder_input_size=1, time_steps=10):\n",
    "        super(DecoderRNN,self).__init__()\n",
    "        self.decoder_hidden_size=decoder_hidden_size\n",
    "        self.encoder_hidden_size=encoder_hidden_size\n",
    "        self.decoder_input_size=decoder_input_size\n",
    "        self.t_steps=time_steps\n",
    "        \n",
    "        self.temporal_attention=nn.Linear(decoder_hidden_size+encoder_hidden_size, 1)\n",
    "        self.rnn=nn.GRU(decoder_input_size,decoder_hidden_size)\n",
    "        self.fc1 = nn.Linear(encoder_hidden_size + 1, 1)\n",
    "        self.fc2 = nn.Linear(decoder_hidden_size + encoder_hidden_size, 1)\n",
    "        \n",
    "    def forward(self,encoded,y_history,batch_size,hidden):\n",
    "        #encoded: batch,T,hidden_size\n",
    "        #print (encoded.size())\n",
    "        \n",
    "        #y_history: batch,T-1\n",
    "        #hidden=self.initHidden(batch_size) #hidden:1,batch,hidden_size\n",
    "        #print (hidden.size())\n",
    "        for t in range(self.t_steps):\n",
    "            x=torch.cat((hidden.repeat(self.t_steps,1,1).permute(1,0,2), encoded), dim=2) \n",
    "            #x:batch,T,enc_hidden_size+dec_hidden_size\n",
    "            x=F.softmax(self.temporal_attention(x.view(-1,self.decoder_hidden_size+self.encoder_hidden_size)).view(-1,self.t_steps), dim=1)\n",
    "            #x:batch,T\n",
    "            x=torch.bmm(x.unsqueeze(1), encoded)[:,0,:]\n",
    "            #x:batch,hidden_size\n",
    "            if (t < self.t_steps-1):\n",
    "                y_tilda=self.fc1(torch.cat((x, y_history[:, t].unsqueeze(1)), dim=1))\n",
    "                output, hidden=self.rnn(y_tilda.unsqueeze(0), hidden)\n",
    "        y_pred=self.fc2(torch.cat((hidden[0], x), dim = 1))\n",
    "            \n",
    "        return y_pred\n",
    "                \n",
    "        \n",
    "    def initHidden(self,batch_size):\n",
    "        return torch.zeros(1, batch_size, self.decoder_hidden_size, device=device)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(encoder,decoder,encoder_optimizer, decoder_optimizer, train_loader, loss_criterion, rl, num_epochs, epoch, epochs):\n",
    "    running_loss=0\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        x=Variable(sample['X'].type(torch.cuda.FloatTensor))\n",
    "        y=Variable(sample['targets'].type(torch.cuda.FloatTensor))\n",
    "        y_true=Variable(sample['y'].type(torch.cuda.FloatTensor))\n",
    "        \n",
    "        encoder_optimizer.zero_grad()\n",
    "        decoder_optimizer.zero_grad()\n",
    "        \n",
    "        hidden=encoder.initHidden(15)\n",
    "        encoded=encoder(x,15,hidden)\n",
    "        hidden=decoder.initHidden(15)\n",
    "        y_pred=decoder(encoded,y,15,hidden)\n",
    "        \n",
    "        loss=loss_criterion(y_pred,y_true)\n",
    "        running_loss+=loss.item()\n",
    "        rl.append(loss.item())\n",
    "        \n",
    "        loss.backward()\n",
    "        encoder_optimizer.step()\n",
    "        decoder_optimizer.step()\n",
    "        \n",
    "    print('Epoch: {}/{} | Loss: {}'.format(epoch-epochs+1, num_epochs, running_loss))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pp(y_pred,y_true):\n",
    "    r=0\n",
    "    for t in range(0,len(y_pred)-1):\n",
    "        if((y_pred[t+1]>=y_pred[t] and y_true[t+1]>=y_true[t]) or (y_pred[t+1]<y_pred[t] and y_true[t+1]<y_true[t])):\n",
    "            r=r+1\n",
    "    return r/len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder,decoder, val_loader, loss_criterion, num_epochs, epoch, epochs):\n",
    "    eval_loss=0\n",
    "    y_predicted=[]\n",
    "    y_actual=[]\n",
    "    with torch.no_grad():\n",
    "        for i,sample in enumerate(val_loader):\n",
    "            x=sample['X'].type(torch.cuda.FloatTensor)\n",
    "            y=sample['targets'].type(torch.cuda.FloatTensor)\n",
    "            y_true=sample['y'].type(torch.cuda.FloatTensor)\n",
    "            \n",
    "            hidden=encoder.initHidden(1)\n",
    "            encoded=encoder(x,1,hidden)\n",
    "            hidden=decoder.initHidden(1)\n",
    "            y_pred=decoder(encoded,y,1,hidden)\n",
    "        \n",
    "            loss=loss_criterion(y_pred,y_true)\n",
    "            eval_loss+=loss.item()\n",
    "            y_predicted.append(y_pred.item())\n",
    "            y_actual.append(y_true.item())\n",
    "            \n",
    "        pred_perf=pp(y_predicted, y_actual)\n",
    "    print('Epoch: {}/{} | Evaluation_Loss: {} | Pred. Power: {}'.format(epoch-epochs+1, num_epochs, eval_loss, pred_perf))        \n",
    "    plt.plot(range(len(y_predicted)),y_predicted,color='red')\n",
    "    plt.plot(range(len(y_actual)),y_actual,color='blue')\n",
    "    #print(len(y_predicted),len(y_actual))\n",
    "    plt.show()\n",
    "    \n",
    "    \n",
    "    return eval_loss,pred_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder=EncoderRNN().cuda()\n",
    "decoder = DecoderRNN().cuda()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_optimizer = optim.Adam(encoder.parameters())\n",
    "decoder_optimizer = optim.Adam(decoder.parameters())\n",
    "criterion=nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rl=[]\n",
    "num_epochs=2000\n",
    "epochs=0\n",
    "for epoch in range(epochs,epochs+num_epochs):\n",
    "    train(encoder,decoder,encoder_optimizer, decoder_optimizer,train_loader,criterion,rl,num_epochs, epoch, epochs)\n",
    "    eval_loss, pred_perf=evaluate(encoder,decoder, val_loader, criterion, num_epochs, epoch, epochs)\n",
    "    if (eval_loss<0.01 and pred_perf>0.5):\n",
    "        print ('%---Saving the model---%')\n",
    "        torch.save({\n",
    "            'epoch': epoch+1,\n",
    "            'encoder_state_dict': encoder.state_dict(),\n",
    "            'decoder_state_dict': decoder.state_dict(),\n",
    "            'encoder_optimizer_state_dict': encoder_optimizer.state_dict(),\n",
    "            'decoder_optimizer_state_dict': decoder_optimizer.state_dict(),\n",
    "            'loss': rl,\n",
    "            },'models/OpenPrice/model_{}.pth'.format(epoch+1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
